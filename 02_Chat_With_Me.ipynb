{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23add92e",
   "metadata": {},
   "source": [
    "# Web Chatbot that Acts Like Me!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5d98f",
   "metadata": {},
   "source": [
    "In the folder `me` I've put a file `Profile.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "I've also made a file called `summary.txt` with a short description about me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d46b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read env key for openai\n",
    "from dotenv import load_dotenv\n",
    "# library to create OpenAI object\n",
    "from openai import OpenAI\n",
    "# to read pdf file and extract text\n",
    "from pypdf import PdfReader\n",
    "# to make the UI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cba99b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "# Create an instance of the OpenAI class\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1fe463",
   "metadata": {},
   "source": [
    "Read the pdf file and extract all text in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6c5dd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "windwatcher17@gmail.com\n",
      "www.linkedin.com/in/ayushi-\n",
      "saxena-416bb9168 (LinkedIn)\n",
      "Top Skills\n",
      "React.js\n",
      "PostgreSQL\n",
      "Django\n",
      "Languages\n",
      "English (Professional Working)\n",
      "Honors-Awards\n",
      "Third Position\n",
      "Certificate of Gratitude\n",
      "Participation\n",
      "First Position\n",
      "Certificate of Appreciation\n",
      "Ayushi Saxena\n",
      "Software Developer at CDSA | Data Science and Applications |\n",
      "Python, Flask, MySQL, Transformers, LLM, RAG\n",
      "Delhi, India\n",
      "Summary\n",
      "Ayushi is a purpose-driven Full Stack Developer who believes in\n",
      "building technology with compassion, inclusivity, and sustainability at\n",
      "its core.\n",
      "She holds a degree in Data Science and Programming from IIT\n",
      "Madras and brings strong experience in application development,\n",
      "data-driven problem solving, and AI-driven innovation. With a\n",
      "foundation in Python, Flask, Django, React, LangChain, SQL and\n",
      "Vector-based databases, she has grown into a versatile developer\n",
      "capable of designing, building, and deploying scalable applications.\n",
      "Ayushi also works extensively in modern AI technologies, including\n",
      "Transformers, Generative AI, Large Language Models, and\n",
      "Retrieval-Augmented Generation (RAG). She has built RAG-\n",
      "powered applications and served as an instructor in an AI bootcamp,\n",
      "where she taught participants about LLMs, prompt engineering, and\n",
      "end-to-end RAG systems.\n",
      "Outside of work, Ayushi is passionate about creative expression like\n",
      "writing fiction, making art, exploring music, and online gaming.\n",
      "Experience\n",
      "Centre for Data Science and Analytics, Ashoka University\n",
      "Software Developer\n",
      "August 2025 - Present (5 months)\n",
      "Setukrite Technologies\n",
      "3 years 1 month\n",
      "Senior Software Engineer\n",
      "April 2024 - August 2025 (1 year 5 months)\n",
      "Web Application Developer\n",
      "  Page 1 of 2   \n",
      "November 2022 - April 2024 (1 year 6 months)\n",
      "Trainee Developer\n",
      "August 2022 - October 2022 (3 months)\n",
      "Tata Steel Adventure Foundation\n",
      "Content Writer Intern\n",
      "July 2020 - September 2020 (3 months)\n",
      "DSKC, Miranda House\n",
      "Research Intern (Chemistry)\n",
      "June 2019 - July 2019 (2 months)\n",
      "New Delhi, Delhi, India\n",
      "Education\n",
      "Indian Institute of Technology, Madras\n",
      "BS, Data Science and Programming · (May 2022 - December 2025)\n",
      "Kirori Mal College, University of Delhi\n",
      "Master's degree, Physical Chemistry · (October 2020 - May 2022)\n",
      "Indian Institute of Technology, Madras\n",
      "Foundation degree, Data Science and Programming · (January 2021)\n",
      "Miranda House\n",
      "BSc (H)- Bachelor of  Science (Honors), Chemistry · (2017 - 2020)\n",
      "St. Anthony's Senior Secondary school  New Delhi\n",
      "Senior Secondary, Science · (2015 - 2017)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "reader = PdfReader(\"me/Profile.pdf\")\n",
    "\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text\n",
    "\n",
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da8db539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the summary text\n",
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bbca1",
   "metadata": {},
   "source": [
    "Setting the prompts:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdf40084",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Ayushi Saxena\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd42b27",
   "metadata": {},
   "source": [
    "*System Prompt*: Defines how the AI should behave overall for the task. It sets the context for the task at hand and the format or the way it should be responded to.\n",
    "\n",
    "*User Prompt*: This is the instruction or question the user types.\n",
    "\n",
    "System prompt always wins if there’s a conflict. For example,\n",
    "* If the system prompt says “don’t give medical advice”\n",
    "and the user says “give me medical advice” → refused or redirected.\n",
    "* If the system prompt says “be concise” → even long user prompts get short answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "483ead7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c332c253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Ayushi Saxena. You are answering questions on Ayushi Saxena's website, particularly questions related to Ayushi Saxena's career, background, skills and experience. Your responsibility is to represent Ayushi Saxena for interactions on the website as faithfully as possible. You are given a summary of Ayushi Saxena's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Ayushi Saxena. I am a software engineer and GenAI expert. I'm from Delhi, currently working in Sonipat, Haryana.\\nI love online gaming. Currently I'm playing Brawl Stars but I also like strategic games like Sid Mier's Civilization series.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nwindwatcher17@gmail.com\\nwww.linkedin.com/in/ayushi-\\nsaxena-416bb9168 (LinkedIn)\\nTop Skills\\nReact.js\\nPostgreSQL\\nDjango\\nLanguages\\nEnglish (Professional Working)\\nHonors-Awards\\nThird Position\\nCertificate of Gratitude\\nParticipation\\nFirst Position\\nCertificate of Appreciation\\nAyushi Saxena\\nSoftware Developer at CDSA | Data Science and Applications |\\nPython, Flask, MySQL, Transformers, LLM, RAG\\nDelhi, India\\nSummary\\nAyushi is a purpose-driven Full Stack Developer who believes in\\nbuilding technology with compassion, inclusivity, and sustainability at\\nits core.\\nShe holds a degree in Data Science and Programming from IIT\\nMadras and brings strong experience in application development,\\ndata-driven problem solving, and AI-driven innovation. With a\\nfoundation in Python, Flask, Django, React, LangChain, SQL and\\nVector-based databases, she has grown into a versatile developer\\ncapable of designing, building, and deploying scalable applications.\\nAyushi also works extensively in modern AI technologies, including\\nTransformers, Generative AI, Large Language Models, and\\nRetrieval-Augmented Generation (RAG). She has built RAG-\\npowered applications and served as an instructor in an AI bootcamp,\\nwhere she taught participants about LLMs, prompt engineering, and\\nend-to-end RAG systems.\\nOutside of work, Ayushi is passionate about creative expression like\\nwriting fiction, making art, exploring music, and online gaming.\\nExperience\\nCentre for Data Science and Analytics, Ashoka University\\nSoftware Developer\\nAugust 2025\\xa0-\\xa0Present\\xa0(5 months)\\nSetukrite Technologies\\n3 years 1 month\\nSenior Software Engineer\\nApril 2024\\xa0-\\xa0August 2025\\xa0(1 year 5 months)\\nWeb Application Developer\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nNovember 2022\\xa0-\\xa0April 2024\\xa0(1 year 6 months)\\nTrainee Developer\\nAugust 2022\\xa0-\\xa0October 2022\\xa0(3 months)\\nTata Steel Adventure Foundation\\nContent Writer Intern\\nJuly 2020\\xa0-\\xa0September 2020\\xa0(3 months)\\nDSKC, Miranda House\\nResearch Intern (Chemistry)\\nJune 2019\\xa0-\\xa0July 2019\\xa0(2 months)\\nNew Delhi, Delhi, India\\nEducation\\nIndian Institute of Technology, Madras\\nBS,\\xa0Data Science and Programming\\xa0·\\xa0(May 2022\\xa0-\\xa0December 2025)\\nKirori Mal College, University of Delhi\\nMaster's degree,\\xa0Physical Chemistry\\xa0·\\xa0(October 2020\\xa0-\\xa0May 2022)\\nIndian Institute of Technology, Madras\\nFoundation degree,\\xa0Data Science and Programming\\xa0·\\xa0(January 2021)\\nMiranda House\\nBSc (H)- Bachelor of  Science (Honors),\\xa0Chemistry\\xa0·\\xa0(2017\\xa0-\\xa02020)\\nSt. Anthony's Senior Secondary school  New Delhi\\nSenior Secondary,\\xa0Science\\xa0·\\xa0(2015\\xa0-\\xa02017)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Ayushi Saxena.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96f72b",
   "metadata": {},
   "source": [
    "Gradio requires a function it can callback to when it needs to process when the user types something in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22df1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{'role': 'system', 'content': system_prompt}] + history + [{'role': 'user', 'content': message}]\n",
    "    response = openai.chat.completions.create(model = \"gpt-4o-mini\", messages = messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "009e946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aaed58",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1e5bd",
   "metadata": {},
   "source": [
    "## Evaluating LLMs using other LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2062ba",
   "metadata": {},
   "source": [
    "Pydantic is a Python framework for data validation and settings management.\n",
    "\n",
    "Pydantic = schema + validation + parsing + serialization\n",
    "\n",
    "Pydantic lets you:\n",
    "* Define data schemas using type hints\n",
    "* Validate and parse input data automatically\n",
    "* Get clear errors instead of silent bugs\n",
    "* Work cleanly with JSON, APIs, and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9910964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e23224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n",
    "evaluator_system_prompt += \"\"\"\n",
    "\n",
    "IMPORTANT:\n",
    "Respond with VALID JSON ONLY.\n",
    "No markdown. No explanations. No extra text.\n",
    "\n",
    "The response MUST match this schema exactly:\n",
    "{\n",
    "  \"is_acceptable\": boolean,\n",
    "  \"feedback\": string\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b9efa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bafa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_prompt(reply, message, history):\n",
    "    return f\"\"\"\n",
    "        {evaluator_system_prompt}\n",
    "\n",
    "        Conversation history:\n",
    "        {history}\n",
    "\n",
    "        Latest user message:\n",
    "        {message}\n",
    "\n",
    "        Agent response:\n",
    "        {reply}\n",
    "\n",
    "        Evaluate the agent response and return JSON only.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f33e474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "\n",
    "gemini = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    "# )\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2e64eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    prompt = build_eval_prompt(reply, message, history)\n",
    "    response = gemini.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    text = response.text.strip()\n",
    "    try:\n",
    "        data = json.loads(text)\n",
    "        return Evaluation(**data)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\n",
    "            f\"Gemini returned invalid JSON:\\n{text}\"\n",
    "        ) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bce88f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As of now, I do not hold a patent. My focus has been more on developing applications and working with AI technologies. If you're interested in my work or projects, feel free to ask!\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "081a0f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The agent accurately answers the question based on the provided context and maintains a professional and engaging tone, offering further interaction.')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "30fbadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58bf032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    # for testing purpose, failing the evaluation\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dbd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The agent's response is in Pig Latin, which is highly unprofessional and inappropriate for the instructed persona of Ayushi Saxena talking to a potential client or future employer on her website. It makes the response difficult to understand and does not align with the 'professional and engaging' instruction.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
